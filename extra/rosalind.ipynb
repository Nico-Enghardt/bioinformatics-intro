{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e717102b-5265-4aa1-89dd-77da3d4d5409",
   "metadata": {},
   "source": [
    "## DNA: Counting DNA Nucleotides\n",
    "Given: A DNA string s of length at most 1000 nt.\n",
    "Return: Four integers (separated by spaces) counting the respective number of times that the symbols 'A', 'C', 'G', and 'T' occur in s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0b37196b-1112-4c50-8b05-d96bf630b5a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: 227 C: 253 G: 234 T: 272\n"
     ]
    }
   ],
   "source": [
    "with open(\"rosalind_data/rosalind_dna.txt\", \"r\") as file:\n",
    "    DNA = str(file.read())\n",
    "nt_count = {}\n",
    "\n",
    "for nt in DNA:\n",
    "    if nt in nt_count:\n",
    "        nt_count[nt] += 1\n",
    "    else:\n",
    "        nt_count[nt] = 1\n",
    "\n",
    "print(f\"A: {nt_count[\"A\"]} C: {nt_count[\"C\"]} G: {nt_count[\"G\"]} T: {nt_count[\"T\"]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2f5a76-dbbd-485e-a66a-84397c05126c",
   "metadata": {},
   "source": [
    "## RNA: Transcribing DNA into RNA\n",
    "Given: A DNA string t having length at most 1000 nt.\n",
    "Return: The transcribed RNA string of t."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2d4bbe0c-ae81-4f1c-a8e7-898f5989598f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAAACGGACAGAGAAUCUACCGCGCAGCUCCCUGUUUCACUAGGUCUCGAGGGGGAGGUAUAGCUCGAGCAUAUAUGAUUUUACGCACAUUGGAUCCAUCCACCGACCGUACUCAAUUCUAAUUGAGCUCACAACGGACGCUCGGUAACCUAUUUUAGAGUAGCUAAGUUUGGGUUCUUAGGGCCUUCUAAGUAUACGGAGUAUCUAUCGUUCAUAAACAACCGGGCGCCGAAGAGACUAAUAUUCUGUGUCCAAAACCGGCCCAAAUAAGCAAUAGCAUUCUAGAAGGCCUGCCGGCUCGAGGGUAGGAAUCUAUCUGGUUUGUAAACUCAGUGUGCUAAGCGGGAAUAUACAGCGAGUUAUCCCGACCCAGCUAGCUGGACUGAGGUGACAGCUCGCGAACUCAAUAUUAGAAGAUGAGCCCCCCUAGCGCCAUCUCACGGCGUUACCAGGCAUCCGAGGAUGAUACUGAAGCAUGACGGCGGAAUUCUCACCUGGCGACGUGCGCCAGGCCGAGAUGCAAAGUACGGCCGCUUGAUCCGGCCUAGCGUUGGUGUGAGUCAGACAUUCAGUUAAGAAUACCAGGGGCGUGCGCACUGGCAGAUUAUAUCGCCCAAGCAUCCGCCAAUUUGGAAGUAUCAUAUCCGUACUCGUUGGGUACAUCGUAGUAUGAGAGCGUGGGCUCCUUGGGGUUCAGUCCAGAGCCGGAAGGGUCCUCGCGCAGGCGAGAGUAGAUUGGUACUCAGCUGCACCACGGAACGCAACAAGGGGUCGUUUCAUGACAUCGAACCUCCAACAGAACUUCAGAUCUUUUCACCGUUUUAUCCUAUUCUCUCCGGGAACAUUGCGUGAGUACUACUUAGAAAGGUACGUAGGUGAUCACCGGGGCUGUCCUAAAGCUGAGGAAGAAAUGCUGCAUAUG\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"rosalind_data/rosalind_rna.txt\", \"r\") as file:\n",
    "    DNA = str(file.read())\n",
    "RNA = DNA.replace(\"T\", \"U\")\n",
    "print(RNA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00cf92d7-a026-43ec-9a2e-3afeb286c2ae",
   "metadata": {},
   "source": [
    "## REVC: Complementing a Strand of DNA\n",
    "Given: A DNA string s of length at most 1000 bp.\n",
    "Return: The reverse complement sc of s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2232fcbc-c23f-4df6-8b9a-0cb7d9fa3282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reverse complement: TATAAGAACGGGAGCTCATTGATCCGAATACCAGCCGTGCGTTTGGCTAGGTGCAAGAGAGCGTTTAGATATTCCTCCATGCGCCCGATGGCTAGTCCGTGTTATATTTTCCAGGGGGGTATTCGTCATCGACTAGGAGACGATGAAACGCTTATTGCAGCGTAGCGACTTCTTATCTTTGTACGTTGTGTAAAGTAGATGCAGAGCCTAAATTTTCACACCTTTAAGTCACAGCATAATCGAACACCCACTATCCCGACGACACACTTCGTTTCTAGCAGACGCCGCAGGGAGTGGTTTTTTGATTCTCGAATGTGGTATGCGAAGTTTAGTAGAACTCGGGCCTGTCACCCGTAGGGAGACGTAAAGGACCTTACCCTGTCCGTCTTACGATCCAGCCGTTACATGCGTAGGCTTGGAGGTCGCCGCGGTCGTTCCAGCAAGGACCGATAGTATGTAAGCCATAGTTTTTTGTTGAATGCGGCGAAGATCTATTACATAATTGAGATACGTGTGCGGCGTGCGGGGTATCGACCCAGATTGCTTACCACCTTGGAGATTGATCATGAATGCGGTACGCGGGAAGCACAGCACCTAAGGAGTAAGGACGTGCAGATTTCCGCACTATTAAATTGGTCTCATGCAATTTAATCGCCTGTTTTGTAGTGCTCGCAGCATGGGCCCCATGGGTTACCTCAGTTAGGAGATCAGATACTGTTGGATAATGCACGTATCGCAGGCATATCCGGATGGGATGATATAATGCCAAGAGAGCAGGTTAGGATATCGCTCCCTCAACGCTGTAAACACGGCGTAGTAGCCTAGGTCACAGACGCTCCATTGAGAATTTCATATGGCCCCCCCACGCCCGTAGGTCCGCTGTGCAATGCACCGGTGTGCCCCAATCAGAGGATCCTCCCCTTCGGTATTAATTACACAGAGACACCGCGTG\n"
     ]
    }
   ],
   "source": [
    "with open(\"rosalind_data/rosalind_revc.txt\", \"r\") as file:\n",
    "    sequence = str(file.read())\n",
    "    sequence = sequence.strip()\n",
    "\n",
    "def reverse_compl(sequence):\n",
    "    sequence = sequence[::-1] #slicing comand that reverses order of characters in string\n",
    "    basepairs = {\"A\": \"T\", \"T\": \"A\", \"G\": \"C\", \"C\": \"G\"}\n",
    "    complement = \"\".join(basepairs[base] for base in sequence)\n",
    "    # looks up value for every key in dictionary \"basepairs\"\n",
    "    print(f\"reverse complement: {complement}\")\n",
    "\n",
    "reverse_compl(sequence)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4adac74-fe26-42b4-a506-40f8f2e2d743",
   "metadata": {},
   "source": [
    "## FIB: Rabbits and Recurrence Relations\n",
    "Given: Positive integers n≤40 and k≤5.\n",
    "Return: The total number of rabbit pairs that will be present after n months, if we begin with 1 pair and in each generation, every pair of reproduction-age rabbits produces a litter of k rabbit pairs (instead of only 1 pair)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b75b58fe-474b-4f83-8926-0bdc6e480507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{357913941}\n"
     ]
    }
   ],
   "source": [
    "def Fibonacci(k, n):\n",
    "    rabbits = [0,1]\n",
    "    for i in range(n):\n",
    "         newborns = rabbits[len(rabbits)-2] * k\n",
    "         total_rabbits = newborns + rabbits[len(rabbits)-1]\n",
    "         rabbits.append(total_rabbits)\n",
    "    print({rabbits[n]})\n",
    "\n",
    "Fibonacci(2, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614cc7ff-0f33-4ce7-ba55-b7722f35c926",
   "metadata": {},
   "source": [
    "## GC: Computing GC Content\n",
    "Given: At most 10 DNA strings in FASTA format (of length at most 1 kbp each).\n",
    "Return: The ID of the string having the highest GC-content, followed by the GC-content of that string. Rosalind allows for a default error of 0.001 in all decimal answers unless otherwise stated; please see the note on absolute error below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c5bba87f-e069-473b-82af-cef8add34148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rosalind_1751\n",
      "52.533040\n"
     ]
    }
   ],
   "source": [
    "# import sequences\n",
    "def fasta_import(filepath):\n",
    "    with open(filepath) as fastafile:\n",
    "        fastafile = fastafile.read()\n",
    "        fastafile = fastafile.replace(\"\\n\", \"\")\n",
    "        seq_list = fastafile.split(\">\")\n",
    "        seq_list = seq_list[1:len(seq_list)]\n",
    "        return seq_list\n",
    "    \n",
    "# directory with each sequence + roslind ID\n",
    "def make_dictionary():\n",
    "    IDs = []\n",
    "    for i, seq in enumerate(seq_list):\n",
    "        ID = seq[0:13]\n",
    "        IDs.insert(i, ID)\n",
    "    \n",
    "    sequences = []\n",
    "    for i, seq in enumerate(seq_list):\n",
    "        sequence = seq[13:]\n",
    "        sequences.insert(i, sequence)\n",
    "    \n",
    "    ID_seq = {}\n",
    "    ID_seq = dict(zip(IDs, sequences))\n",
    "    return ID_seq\n",
    "    \n",
    "# determine GC content of single sequence\n",
    "def GC_content(sequence):\n",
    "    total_GC = sequence.count(\"G\") + sequence.count(\"C\")\n",
    "    share_GC = total_GC/len(sequence)*100\n",
    "    return share_GC\n",
    "\n",
    "# bring all together:\n",
    "filepath = \"rosalind_data/rosalind_gc.txt\"\n",
    "seq_list = fasta_import(filepath)\n",
    "ID_seq = make_dictionary()\n",
    "GC_share = []\n",
    "\n",
    "for ID, seq in ID_seq.items():\n",
    "    GC_share.append(GC_content(seq))\n",
    "\n",
    "ID_share = dict(zip(ID_seq.keys(), GC_share))\n",
    "\n",
    "top_GC = dict(sorted(ID_share.items(), key=lambda item: item[1], reverse=True)[:1])\n",
    "for key, value in top_GC.items():\n",
    "    print(f\"{key}\\n{value:.6f}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbf35c0-6c6b-4d9a-855d-8d5b1e23609e",
   "metadata": {},
   "source": [
    "## HAMM: counting point mutation\n",
    "Hamming distance =  #nucleotides that differ between strings of same leng\n",
    "\n",
    "Given: Two DNA strings s and t of equal length (not exceeding 1 kbp).\n",
    "Return: The Hamming distance dH(s,t)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "33b27aa1-a813-4880-adb9-e62de8e5331e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "452"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import sequences\n",
    "with open(\"rosalind_data/rosalind_hamm.txt\") as file:\n",
    "    seq = file.readlines()\n",
    "    seq1 = seq[0]\n",
    "    seq2 = seq[1]\n",
    "\n",
    "# calculate Hamming distane\n",
    "def Hamming_distance(seq1, seq2):\n",
    "    unequal_test = []\n",
    "    for nucleotide in range(len(seq1)):\n",
    "        comparison = seq1[nucleotide] != seq2[nucleotide]\n",
    "        unequal_test.append(comparison)\n",
    "    return sum(unequal_test)\n",
    "\n",
    "Hamming_distance(seq1, seq2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5fca26-9815-46fa-9e40-67b5192eb009",
   "metadata": {},
   "source": [
    "## IPRB: Mendels First Law\n",
    "given:\n",
    "\n",
    "k = homozygot dominant Individuals\n",
    "\n",
    "m = heterozygot Individuals\n",
    "\n",
    "n = homozygot recessiv Individuals\n",
    "\n",
    "wanted: probability P of 2 random individials producing dominant phenotype child"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1b2510c0-15ec-4185-9778-fb70ffd3ab8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7681121099947118\n"
     ]
    }
   ],
   "source": [
    "# define share of dom phenotype in offspring\n",
    "Dkk = 1\n",
    "Dmm = 0.75\n",
    "Dnn = 0\n",
    "Dkm = 1\n",
    "Dkn = 1\n",
    "Dmn = 0.5\n",
    "share = [Dkk, Dmm, Dnn, Dkm, Dkn, Dmn]\n",
    "\n",
    "# given number of pairs\n",
    "k = 18\n",
    "m = 28\n",
    "n = 16\n",
    "total = k + m + n\n",
    "\n",
    "# probability of drawing each pair\n",
    "Pkk = k/(total) * (k-1)/(total -1)\n",
    "Pmm = m/(total) * (m-1)/(total -1)\n",
    "Pnn = n/(total) * (n-1)/(total -1)\n",
    "Pkm = (k/(total) * (m)/(total -1)) + (m/(total) * k/(total -1))\n",
    "Pkn = (k/(total) * (n)/(total -1)) + (n/(total) * k/(total -1))\n",
    "Pmn = (m/(total) * (n)/(total -1)) + (n/(total) * m/(total -1))\n",
    "Pdrawing = [Pkk, Pmm, Pnn, Pkm, Pkn, Pmn]\n",
    "\n",
    "# total probability\n",
    "result = [a * b for a, b in zip(Pdrawing, share)]\n",
    "print(sum(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9128131-1267-4f3f-859b-d76b232b07c7",
   "metadata": {},
   "source": [
    "## PROT: translating RNA into protein\n",
    "Given: An RNA string s corresponding to a strand of mRNA (of length at most 10 kbp).\n",
    "Return: The protein string encoded by s.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "efe24c6e-e650-4f33-89b1-cc398c343a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop codon reached at triplet number 3118\n",
      "MVHCCTRAAGQTNSRPGRFPDAISCRRGLPAQPG LQPEVGADDLIIQNVSQILVSFVDPSVNRANRVAAQLTAGRIASG NLCAGCVFRVALRSAPSQVRCIRTYNEKASLAPKILTSCVSNSPASTWHADPRPRVYKRSYCRTMGAGRPAAAQCSKVALFRFFLVPSLACPIAWSPVLPLDALRGPYPDLAAPYTREWVSRFRKQSVIEFTTLLYLIHPHSYGQPVEILEVAQIHQPNKFARRATG AG LWNLLLYLPITLFQGIIECSASAAVPARPAATKAGRSCDLRHAMPLLCRICTLIAPCYFGSSSACRLFQCFNFVRVRG LCRASNTSGHSELRVGHRSRRWRHFARKLLLTWLACVNHRRWLGLTFQVRSGG TVFASDRVG GSQSPSNVRSNLQMGG YPRLYEQQDVTWRKRCLEPGPSIPSSVTMGSHKRIESLVLQYIFIHHLCECYRACTVGSSPSKSVRFTTSFLKTHILTSVKMRPTRVPWRLYGVDSQNECHTEELAHCQLDQKAKVLLPLDSLIIGLPSSVPVG TTSTNFWNLAVNNAFEKFDGSG LAVQPCAAVG GHARTALPG EISSATHSTAMCKVSVRMRKGGSVEQHSRPSRVPVCTRKGIIALAELENLRRLCGESSTDPANLAIQCCEAANTPWVYRLRRYEYIAADGFRHFSRCLKTKGNSHHPKLIALRATWPEFALKQHPACNAALAVDNYPRCPMWGCHRLVMYDNSFLGICVLRIKYMWRG TIAVIG DVG YISWAPTCRMSSGESFRLDMVNPWLSPQLSAQNLAARVHRSVATNIMLLSAFSFSTLFARRCKVPGIGRTALEHGTFVRPTTTPGGVWMTDYLHNNPVYKSRRAQTEAKRRANYKVRTRSIYCLSYTRPRASAQWALVSRAMDLVMGSFDNNFFLTTQGSLVSSSQRLRRVKGTCLPG GWIKTVRPRRRSCSLARYKVGKSALNDTTEVTGPLPG NICAHEDYRSCALRFAFSAWDVFRRAMYNGYAYQPLSQPITFYAALSDYNHLPPDPIPLSTPFLLENMYETLGVRAVHDTVG WLECFLIQATVPQHEAALTYTLSSPMLGTLQELPVGSKITLYLGWPLGILLIVNRSTLRPVGGVARG NGTVG SNTLG RRCPIQQCTGRNCGFYLARIEFLVPPVVCAQRYRNNGHTTTRVLVPHKLSLRSESRIYRSSLTFSTSSSMRSPQSGYRSSPGAIELWTLLGSLSLPPTARG HLQGRCLIG CKLCTQRGESRSPVHRSDAACMPYVKSPSKVDDLPPGWAVRGRSGVDCVAKATRFAVIVWDARRVRAFLIHGNPSYAAIKWCFKITPHPCWWHIRGRNDRQIQPSASCVRIFRSTKITNHHDIPHYIPPYRVWNAAHSSSNCHSDVSGFTRAVSRRRSAFANDITVSSG VG VLKYALLCYPVGSSYLSSCLLELFSRRILTFALANYVMYIIIGASSFNIAGPCKNLKYTVATISLVRLPNERLLKEIGKGGNAQFHG PGRPIRVRTCLPKVPDTGAYDRVCLSKACPSTLARSQYYTASPLGWSDQPYARFMG ISDRSEATNRKYPGPEFRRLEGCRGPRDIAYSRQYDNVEMPNLGVACNSSAKGVNKTVTGWSTLGRIKSLTTIWGYMEYSRSPSKSNRSGIQFKLSLRSKDLVTNTNFARPTSVHLQSRISEYFGSLNGYVRVRNLASVPVDCPRPPAPTLPEATGDSGVLVEG SAG RWRWNILYTSADGLRTSGFRKVEPRGGAKWEHHVPHLQPG TLWGRRMTCLLFEEKMFQLLRQSPIQIDAPLHSG VCTRRAVEAHGSTGAVIVG ADRNSSARDGLRTVLRGIQRVIVEAHSSVIDAMYDYCSLLSFIIADILIHQGMPHLLKQVLWRSVRHDLSRQTTYSRTGGDIFNVPIQG DAGRKFLRPTLKGRTQRTTG ALSLVDCDWHRNEPRHSVSQYHFGIATMRLFSVRLYEYNDRNTSRKGASIECEG IGLSFDRGRPLCSFAVIRVRQITQQVKLWSELCATGERMYVMIPAYDLTTALRKPKQTIMKILPGPASMALTIRAECTRVPTLFTLTLLVG VRTVLCGQNNLGNSTPYGFPGIVSCHCGVRNRRSLHLSRGGAKRFQMCVLRHLRWSSHHKVSQSHYFPLVATHPLRRRARDWILKSVVKCAASRQCYAIMSPLNPSWSRTQRSAFVRRRPLPSKYKTTTHYSTPGHERRSCFALKVSCVSVWFGRARCNPLQARAGEQLKKYRNALVRSTNSEGLEFSG HQCPWIYLTSRSCRNASKNTSTDALEMTYDPREEACSRGIAG ATVLHARRPPDAAG SWLVRVSPLSPEAVSWWEG G NRHYCKAACDHNMDTFVFAWATQNQRLRVSSLETTLCRRRSSTEWGIRSNLGLGVVARYRESPFDWYQSAWHFSQGLQSGTCPKPTAHNPGRSDPLERARFKLDRYYPRSTNVHGGNFCDATRRHKELPRIALRSTHATDSELLTPACREVRSDRTSRLVYQATLGG APTTTSAINVGCRAKLRTKIGGPARNRLASRPAYGHSLARIVPPQGSNSDKLRRGHLSAQDRACYLLVSHQFVRLHAGKFGVLPIYHVNHLRPARPPPKGAQTRPGPIHLYCTQGVVRFFLHRQSTRKTRRRNICVLCRVADNMRRMRPIRNPRCFECVCVPTPIERLVYGLVDPRRGLTEWQLLSLLVSNYPNITQFLPHRFTRMQIQAALLYVVRWKHNISYEG HEFSKEVERERWFCIDGCCHTWMHTQLYTTNLRRIFQLKVIPAILKVSLQGRCSPRMIRRTIRLGSRYKTVLGTTQRHFNPYRAIRASRPEIHSTMVDRCLRTSTNICLVVGMVLHRPLRAITCNCESLERRPELDKAPCEG EVSRRCRGESQISSVYATLFQCFPNLSAYSRDSYRDALHWADKFKNERLFYRQMSGLLGAMSFRPQSVRIQAGISTCARKG QSCYRSTTLKEYFTIITIDRLQADYSSRPLQNGGSISKLYAVTATLRDVQSMDNISLLFLGTPRSRMGHITMAASSG MIRSAVPHSIDGLEFLDTLLGKLG SSLCSIG AMRGDPVSSG SLVEPSLCLGPDSRCSLLPTGRSHQNLNRPVVINAPYQATITVKYLVAIGFStop\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# make dictionary to look up AA for each triplet\n",
    "with open(\"rosalind_data/rosalind_codon_table.txt\") as file:\n",
    "    table = file.read()\n",
    "    table = re.sub(r'\\s{2,}', '\\n', table)\n",
    "    # re replaces whitespaces (=\\s) that occur at least twice {2,}'\n",
    "    table = table.split(\"\\n\")\n",
    "    codons = []\n",
    "    AAs = []\n",
    "    for line in range(len(table)):\n",
    "        codon = table[line][0:3]\n",
    "        codons.append(codon)\n",
    "        AA = table[line][4:]\n",
    "        AAs.append(AA)\n",
    "    code = dict(zip(codons, AAs))\n",
    "    \n",
    "# define function for translation\n",
    "def translate(filepath):\n",
    "    # read RNA sequence\n",
    "    with open(filepath) as file:\n",
    "        seq = file.read()\n",
    "        start = seq.index(\"AUG\") # .index returns index of first occurence\n",
    "        seq = seq[start:]\n",
    "        triplets = [seq[i:i+3] for i in range(0, len(seq), 3)] # 3 as steps in range needed  \n",
    "    # translate RNA into protein\n",
    "    AAseq = []\n",
    "    for i in range(len(triplets)):\n",
    "        AA = code.get(triplets[i])\n",
    "        if AA == \"Stop\":\n",
    "            AAseq.append(AA)\n",
    "            print(f\"Stop codon reached at triplet number {i}\")\n",
    "            print(\"\".join(AAseq))\n",
    "            #return AAseq\n",
    "            break\n",
    "        else:\n",
    "            AAseq.append(AA)\n",
    "\n",
    "translate(\"rosalind_data/rosalind_prot.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e939b5-c137-40a8-bce8-f3a9d6b0865d",
   "metadata": {},
   "source": [
    "## SUBS: finding a motif in DNA\n",
    "Given: Two DNA strings s and t (each of length at most 1 kbp).\n",
    "Return: All locations of t as a substring of s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0b27f7ad-24c4-4231-9c39-30110626f263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'AAGTTCCAA' found at indices: \n",
      "2 9 76 121 137 182 201 219 231 264 272 297 378 385 440 458 491 530 547 563 583 591 598 622 629 662 669 699 706 725\n"
     ]
    }
   ],
   "source": [
    "with open(\"rosalind_data/rosalind_subs.txt\") as file:\n",
    "    file = file.readlines()\n",
    "    sequence = file[0]\n",
    "    sequence = sequence.replace(\"\\n\", \"\")\n",
    "    motif = file[1]\n",
    "    motif = motif.replace(\"\\n\", \"\")\n",
    "\n",
    "# function to find motiv\n",
    "def motif_finder(sequence, motif):\n",
    "    import re\n",
    "    matches = [match.start()+1 for match in re.finditer(f\"(?={motif})\", sequence)]\n",
    "    # \"(?={motif})\" makes function able to find overlapping motifs\n",
    "    # +1 because python starts counting at 0\n",
    "    # re.finditer needed to find ALL matches in seq not just first\n",
    "    # .start() retrieves first index of match\n",
    "    \n",
    "    if matches:\n",
    "        print(f\"'{motif}' found at indices: \")\n",
    "        print(\" \".join(map(str, matches))) #map applies str to each element of matches\n",
    "    else:\n",
    "        print(f\"'{motif}' not found\")\n",
    "    #return matches\n",
    "\n",
    "motif_finder(sequence, motif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f2b6f5-6db5-4336-aae5-0929e7e3f900",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "33097ad0-9f30-4c9a-9db6-99a03b0236a1",
   "metadata": {},
   "source": [
    "## CONS: Consensus and profile\n",
    "Given: A collection of at most 10 DNA strings of equal length (at most 1 kbp) in FASTA format.\n",
    "\n",
    "Return: A consensus string and profile matrix for the collection. (If several possible consensus strings exist, then you may return any one of them.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "bb494f8e-e700-4a2a-a8a5-073e9129f238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: 3 0 2 1 2 1 2 0 2 1 5 4 2 2 2 1 2 2 1 3 3 1 1 4 2 2 0 2 0 3 1 4 2 3 2 1 4 2 1 2 2 3 3 2 5 3 1 4 2 1 1 4 2 3 3 2 4 3 0 4 5 2 3 2 2 3 1 3 3 3 2 5 1 3 3 2 5 1 3 2 3 4 2 3 3 1 1 3 2 3 2 3 3 3 5 2 2 5 3 0 3 2 4 4 0 1 2 2 2 4 2 5 2 4 1 2 0 2 2 2 4 0 2 3 1 3 3 1 2 2 2 0 3 1 3 3 2 2 1 2 2 2 2 2 0 1 2 1 3 2 4 3 4 3 3 2 4 4 4 1 1 2 2 1 1 2 2 3 5 4 4 5 4 3 1 2 4 3 2 2 2 3 4 4 5 3 2 2 3 1 4 5 2 3 1 3 4 1 1 1 2 4 2 5 3 1 2 2 1 1 1 2 1 2 3 5 0 3 3 2 1 0 3 4 1 3 2 3 3 1 1 1 3 2 2 4 3 1 3 2 3 1 3 2 1 4 1 3 2 3 3 6 4 1 4 2 3 4 2 1 1 4 4 3 0 4 2 4 3 2 2 3 5 4 2 3 2 1 4 1 2 0 1 1 1 2 5 2 3 2 3 1 6 2 1 2 3 3 3 3 5 3 3 3 3 2 3 5 0 1 3 1 2 5 4 4 2 5 3 1 3 3 1 1 1 3 6 4 4 2 3 2 6 2 2 1 3 2 2 1 3 3 5 5 2 3 0 2 1 3 4 1 2 3 3 4 3 5 2 3 1 3 0 5 2 4 2 2 1 5 2 1 4 2 3 1 2 1 6 1 1 3 4 3 4 3 5 1 2 2 3 2 3 2 2 3 2 4 3 1 2 1 2 3 3 3 0 4 2 2 2 5 2 4 2 4 3 0 1 2 1 1 3 5 3 2 2 7 1 5 1 3 2 5 4 3 5 1 4 3 3 4 4 4 2 2 1 1 1 3 1 1 2 2 1 1 3 5 3 3 1 2 3 1 3 5 3 3 2 2 3 1 3 0 3 4 7 1 2 1 4 4 0 2 0 2 5 1 4 5 3 2 4 4 4 1 1 4 4 3 2 5 1 2 3 2 0 3 2 1 3 3 3 2 1 0 4 7 4 2 3 3 3 3 6 6 3 2 3 2 3 5 4 2 2 4 4 2 5 2 4 3 2 2 4 5 2 2 3 1 1 3 3 1 1 2 3 3 4 3 3 4 1 5 1 3 4 3 4 1 4 2 3 2 1 2 3 2 3 2 1 1 3 3 3 1 3 3 4 1 1 1 2 4 2 1 0 3 4 0 3 2 3 5 1 5 3 2 3 2 1 2 1 3 0 2 3 1 5 1 2 1 3 3 1 2 2 3 3 4 3 1 0 2 3 3 4 3 6 3 2 3 4 1 1 3 2 0 3 2 3 4 5 3 4 2 5 2 3 3 5 2 2 4 2 3 3 1 3 4 2 3 1 2 3 3 3 3 2 2 2 1 1 3 1 3 0 3 2 2 0 2 4 2 2 1 0 2 5 2 0 3 2 3 2 4 0 1 4 2 4 1 3 4 1 2 2 5 2 4 2 2 1 3 2 2 3 2 0 1 0 2 3 1 2 3 2 4 2 4 5 1 3 2 2 2 3 2 2 3 3 2 2 2 2 4 2 4 1 0 3 3 1 2 0 3 2 3 3 3 2 5 0 4 3 1 2 3 3 4 1 4 5 1 3 3 2 3 2 1 2 3 0 1 4 2 0 1 2 1 1 2 2 2 3 3 2 2 1 3 4 2 4 2 2 4 4 3 2 4 2 2 4 3 1 3 2 0 2 6 2 1 3 2 1 2 5 2 1 1 2 2 3 1 3 2 1 6 3 4 1 1 1 2 2 2 5 2 2 2 1 2 2 0 1 2 1 5 2 1 3 2 3 2 1 2 2 4 1 4 2 2 1 2 4 2 4 3 5 2 2 1 4 1 4 4 3 3 2 3 5 1 4 0 3 4 2 1 2 2 1 1 4 0 2 1 1 4 3 2 3 2 3 3 4 4 3 1 5 2 4 2 2 3 2 2 4 3 2 6 1 1 1 0 1 2 5 1 4 2 1 3 5 1 3 3 3 6 4 2 2 1 1 4 4 4 0 3 6 0\n",
      "C: 2 7 3 3 1 2 4 3 1 1 1 3 2 1 3 4 2 2 3 4 2 2 4 2 6 3 3 4 4 2 5 2 1 3 2 4 3 3 4 4 1 0 3 2 3 1 5 0 2 3 2 1 1 1 2 2 2 2 4 0 1 3 3 2 1 1 5 1 1 3 3 0 2 2 2 3 2 3 3 4 2 1 3 1 3 4 3 4 1 2 3 3 4 1 1 1 3 1 3 5 5 1 3 1 4 3 3 2 4 3 6 1 3 2 2 1 2 3 3 2 3 3 6 2 2 1 1 4 4 1 4 1 1 2 1 5 1 3 1 4 3 1 3 2 5 1 3 2 2 3 2 2 2 2 4 4 4 1 4 3 4 2 4 0 4 3 1 2 0 2 4 1 3 2 5 3 1 2 3 2 2 1 1 2 2 2 2 4 3 3 2 2 5 4 3 2 2 3 3 3 1 3 3 4 2 5 3 1 3 2 4 5 3 2 2 1 1 1 1 5 4 4 2 1 1 6 0 3 4 2 3 3 3 5 4 5 1 2 3 5 1 5 4 1 2 2 5 4 2 2 2 2 2 3 3 4 1 2 4 6 4 3 2 1 1 2 1 1 3 2 1 5 3 5 3 4 2 6 4 2 2 6 5 3 2 3 2 3 4 3 5 2 0 3 2 4 2 1 2 3 2 2 0 4 1 5 4 2 3 3 1 2 1 1 0 3 5 2 3 4 5 4 2 2 4 2 2 2 2 3 1 4 2 2 3 5 2 5 2 5 4 3 3 0 2 3 3 2 5 2 1 3 3 1 2 1 2 4 2 2 1 4 3 1 1 2 4 3 1 2 3 3 2 3 1 4 3 1 2 0 2 3 1 4 3 4 1 2 0 3 4 1 1 5 1 3 2 1 1 7 2 2 4 0 2 1 2 1 2 2 2 1 3 4 2 0 1 3 2 2 3 1 3 2 1 2 3 1 3 3 1 1 2 3 4 4 1 4 2 2 3 1 2 2 3 6 2 4 4 0 3 2 3 3 4 2 0 2 4 2 2 2 2 2 3 2 5 1 4 5 1 7 1 1 1 0 2 3 2 3 3 2 2 3 3 3 2 2 4 1 2 0 3 1 1 4 3 3 2 1 3 1 1 2 4 2 4 2 5 5 2 2 2 3 5 3 1 1 4 0 1 4 2 0 2 2 3 4 2 3 2 0 1 4 3 2 0 1 1 1 1 2 3 5 4 4 0 4 1 3 4 2 1 5 4 5 1 2 6 4 1 4 6 1 1 0 2 2 3 2 4 4 1 3 3 5 1 2 3 3 2 5 2 1 4 2 3 4 4 5 3 5 4 2 4 2 1 2 5 3 0 4 3 1 2 2 0 3 4 1 3 3 3 3 5 4 2 3 1 5 3 5 4 4 5 1 3 3 2 2 2 0 3 2 4 4 2 4 2 4 2 4 1 4 4 0 5 2 4 5 3 1 1 0 1 2 0 6 2 3 2 1 2 2 3 3 3 2 2 2 3 0 2 1 2 0 1 2 2 2 2 1 3 0 2 5 4 1 2 5 3 2 2 3 4 4 4 3 2 3 3 2 5 3 4 3 3 4 1 3 1 4 3 3 3 2 2 1 3 3 4 4 4 2 5 3 0 3 5 3 2 0 3 4 2 1 4 1 4 3 2 1 2 2 3 0 3 4 1 1 3 4 2 2 3 2 3 1 0 5 4 3 4 3 3 2 4 1 1 4 4 3 3 2 2 2 2 2 2 2 2 1 2 1 2 2 3 3 3 2 3 4 2 4 2 0 5 3 5 2 3 3 2 3 2 2 0 2 3 0 3 3 0 3 4 2 2 1 0 2 3 2 4 2 2 3 6 4 3 0 1 4 2 4 2 4 1 3 2 3 3 0 1 3 1 2 5 1 3 2 1 4 4 3 2 1 3 6 2 2 3 2 2 4 4 4 1 2 2 5 0 4 3 1 4 4 2 0 4 0 2 2 5 6 1 5 4 2 1 2 1 2 4 2 1 2 4 3 3 1 1 4 1 3 2 3 5 4 3 4 3 4 1 4 3 3 1 3 4 2 1 3 2 1 3 2 2 3 1 5 3 4 0 1 3 2 1 3 2 1 4 0 1 3 3 3 3 3 3 1 4 2 0 5 2 2 2 2 2 4 2 3 3 2 3 2 4 2 1 5\n",
      "G: 1 3 2 4 2 2 2 4 2 2 3 1 5 3 1 1 1 5 4 2 1 1 2 2 2 2 6 2 2 2 0 3 4 2 4 4 1 3 3 4 3 3 3 1 1 3 4 2 3 4 2 2 2 4 3 3 3 3 4 1 1 4 3 2 2 2 2 1 2 2 4 2 3 3 1 4 1 3 2 2 2 2 2 2 3 0 2 1 4 5 3 1 3 2 2 2 3 3 3 2 1 4 2 5 2 4 3 4 2 3 1 4 0 2 6 2 6 4 2 3 2 1 1 4 1 3 4 1 1 4 2 4 1 2 3 0 3 1 5 2 1 5 3 1 2 5 2 4 0 3 2 4 1 3 1 1 1 4 1 3 2 2 2 4 4 3 3 3 5 3 0 2 1 2 2 5 4 4 2 3 2 3 4 3 1 3 4 3 2 5 1 2 1 1 4 4 3 2 4 5 5 1 3 1 3 0 3 2 1 3 5 2 1 1 2 3 6 4 1 2 2 2 3 2 5 0 5 2 2 4 2 3 3 1 2 1 4 6 3 2 5 3 1 6 3 2 1 3 4 1 2 1 1 2 0 1 1 2 1 2 3 1 2 4 5 1 3 2 3 3 5 0 0 0 1 2 1 2 1 3 2 3 4 4 3 2 2 2 1 3 1 5 2 5 5 2 3 3 2 0 2 3 5 3 2 0 2 2 4 3 4 4 5 1 2 2 1 1 2 4 1 0 6 4 3 1 2 3 2 3 4 4 0 3 2 2 0 2 3 2 1 3 0 3 3 1 4 3 1 2 3 4 3 1 2 2 1 0 2 3 6 2 2 2 4 2 2 2 4 2 3 3 1 2 3 4 2 6 1 4 2 2 3 2 1 1 1 4 4 4 1 3 5 2 4 3 4 1 3 0 3 2 3 1 3 4 6 2 6 5 5 3 2 1 2 4 3 5 3 4 5 5 2 1 3 0 3 1 4 0 2 4 3 1 2 1 1 3 4 3 2 2 3 1 1 1 4 3 3 2 2 4 4 2 3 4 5 3 2 1 1 2 2 1 0 3 1 2 1 0 4 1 4 3 4 1 1 5 4 2 0 1 6 5 6 3 3 3 2 3 1 4 1 2 3 2 4 3 2 3 1 3 5 2 2 2 4 3 1 3 1 1 3 1 3 3 2 1 1 4 3 2 3 5 1 1 4 3 3 4 3 3 3 1 2 2 3 3 3 6 2 3 4 1 1 1 3 2 3 1 2 2 3 2 1 0 4 3 0 0 3 1 1 3 2 3 2 2 1 5 1 2 1 3 6 2 4 3 3 2 4 1 3 4 1 5 4 3 1 2 4 3 2 1 3 5 4 3 0 3 4 3 4 0 2 2 5 2 0 2 3 2 1 2 4 3 4 3 0 2 4 3 3 2 2 2 5 2 1 1 2 6 5 3 2 1 3 0 1 2 5 3 3 3 2 3 0 5 0 1 3 2 0 3 4 1 2 0 4 2 3 3 4 3 2 2 1 4 2 1 0 3 3 4 3 5 4 1 2 4 4 4 4 3 2 2 1 3 5 2 6 3 2 2 3 2 2 3 2 2 3 1 2 2 4 2 2 3 3 2 3 4 0 2 4 2 3 2 0 2 2 2 2 2 2 4 2 3 3 5 3 3 2 1 1 2 2 2 2 2 2 5 3 2 4 5 4 2 5 3 0 2 2 2 1 0 4 4 4 2 2 2 3 5 4 4 3 2 1 2 2 2 5 0 1 5 5 1 1 3 4 2 1 6 4 1 4 0 1 6 2 2 4 1 2 3 1 3 2 2 3 3 2 1 2 2 2 3 3 3 2 3 4 2 2 2 2 5 5 2 1 4 2 3 4 2 1 1 5 3 1 3 1 1 4 2 3 2 3 3 3 5 3 3 2 3 2 2 3 2 4 4 4 2 4 4 1 0 4 2 2 3 3 0 2 4 1 0 6 2 3 1 3 3 4 1 2 3 1 3 4 5 4 2 3 0 1 1 3 3 3 4 1 3 3 2 2 3 3 3 3 2 3 3 3 2 1 4 1 2 3 3 1 2 3 4 3 2 1 4 3 2 4 2 3 3 2 1 3 1 2 2 2 2 4 3 2 2 5 2 3 3 4 3 2 2 1 1 2 2 1 2 3 3 2 3 2 2 1 1 4 4 3 3 1 2 5 2 3 3\n",
      "T: 4 0 3 2 5 5 2 3 5 6 1 2 1 4 4 4 5 1 2 1 4 6 3 2 0 3 1 2 4 3 4 1 3 2 2 1 2 2 2 0 4 4 1 5 1 3 0 4 3 2 5 3 5 2 2 3 1 2 2 5 3 1 1 4 5 4 2 5 4 2 1 3 4 2 4 1 2 3 2 2 3 3 3 4 1 5 4 2 3 0 2 3 0 4 2 5 2 1 1 3 1 3 1 0 4 2 2 2 2 0 1 0 5 2 1 5 2 1 3 3 1 6 1 1 6 3 2 4 3 3 2 5 5 5 3 2 4 4 3 2 4 2 2 5 3 3 3 3 5 2 2 1 3 2 2 3 1 1 1 3 3 4 2 5 1 2 4 2 0 1 2 2 2 3 2 0 1 1 3 3 4 3 1 1 2 2 2 1 2 1 3 1 2 2 2 1 1 4 2 1 2 2 2 0 2 4 2 5 5 4 0 1 5 5 3 1 3 2 5 1 3 4 2 3 3 1 3 2 1 3 4 3 1 2 2 0 2 1 1 1 1 1 2 1 4 2 3 0 2 4 3 1 3 4 3 3 5 2 3 1 2 2 2 2 4 3 4 3 1 3 2 2 2 1 4 1 5 1 1 4 4 1 0 2 4 3 1 3 2 2 1 2 2 0 2 2 2 3 3 4 1 2 2 0 4 3 1 1 3 3 2 3 2 3 4 1 2 2 2 1 1 3 1 3 2 4 0 1 2 2 2 0 2 3 3 2 5 1 3 2 2 1 2 2 3 3 3 3 3 3 2 2 2 5 3 3 4 1 4 2 2 1 5 2 3 2 2 3 4 1 2 3 3 3 3 1 3 2 1 5 5 2 2 1 2 2 3 3 4 1 2 4 1 1 3 1 2 4 3 2 3 5 1 6 2 2 2 3 0 1 1 1 3 1 4 2 3 2 4 2 1 3 2 2 3 6 2 1 2 2 6 2 3 1 0 2 3 2 0 2 2 3 1 3 4 1 3 2 2 5 4 3 1 3 2 3 2 0 1 4 6 4 3 6 4 0 1 4 3 3 2 1 2 6 2 5 0 1 2 4 3 3 2 0 1 2 0 4 0 1 4 4 2 3 2 3 2 0 2 3 4 1 3 4 1 4 2 2 2 1 4 4 2 4 1 4 3 1 1 4 3 1 2 2 1 1 0 1 2 1 2 2 2 3 3 2 3 4 1 1 3 2 1 2 1 0 5 2 3 5 3 3 3 2 4 3 2 2 0 3 3 1 2 1 6 4 2 3 2 2 1 2 5 2 0 1 2 3 1 3 3 3 2 2 2 2 0 0 1 2 2 1 2 3 1 2 5 2 1 4 3 1 0 4 5 1 2 3 3 5 3 3 5 2 1 1 1 3 4 2 1 1 0 1 2 5 0 2 4 3 3 3 2 3 1 2 1 3 1 1 1 0 2 2 3 4 3 3 3 2 1 3 4 4 1 5 3 2 1 2 0 4 2 1 3 2 3 3 3 3 5 4 4 3 2 2 2 4 4 2 2 4 2 4 5 0 5 3 1 1 1 3 2 3 1 3 4 2 1 3 4 4 1 2 0 1 5 2 2 3 2 1 4 1 2 4 3 2 5 1 2 2 3 3 1 1 5 2 2 1 5 5 2 4 5 4 2 3 2 1 1 3 2 4 1 3 0 2 2 3 4 2 4 4 4 4 1 1 5 3 1 2 2 0 3 1 1 4 5 1 2 0 2 4 4 2 1 4 4 1 3 3 2 2 1 4 1 4 4 1 3 1 4 4 2 5 4 3 1 5 3 2 4 4 3 3 6 3 3 4 1 2 2 3 2 2 2 1 3 2 4 2 0 2 3 2 1 5 0 1 6 2 4 3 3 2 1 3 4 3 2 3 3 3 4 3 2 1 1 2 4 1 1 3 2 3 1 2 2 4 4 3 3 6 3 0 7 3 0 2 4 3 1 4 1 3 4 3 4 3 2 1 0 0 2 3 1 4 1 3 4 3 1 4 2 2 1 1 2 3 1 3 2 4 2 1 2 1 4 2 3 2 4 4 2 2 5 1 2 2 3 3 1 4 0 1 3 5 1 2 1 2 6 4 1 3 3 2 1 1 2 6 4 4 4 3 1 5 1 5 4 3 2 1 3 2 3 0 3 3 2 2 3 1 2 2 1 3 0 2\n",
      "SOLUTION:\n",
      "TCCGTTCGTTAAGTTCTGGCTTCACCGCCACAGAGCACCCTTATAACAGGTATGAGAACTAGATTTCTTAGATATGACACAACTATTCGGCACTATCAACCGAGCGCGCACATAGTGGCGATCGTAGCCGCTTTACTTGCTGCTCGCGTCAGAACCAAACCTCTCCTAAAAAAACGAGCGTAAAAAGCAGAACCGGATGGGACAACCTTTGCTTAAGGTCCCAAGCGACGTCACCCGGACGCCGTACCGTAAATACTACCCAAGGATAAGGCACTCTCATTCCGTCACCCCGAGGCAAATAAGCTCCAGCGGGAAACAACCCGGCTAAACGCAGCCTCGCCAAAGAGGCAAGCTAATATAGCTAGACCGACCACACCGATTAACACAGGGCTGCGAGAACGTCTAGGAGGGACATAAGTGGGAAATCAGATGGAACACAAAAAATCGCCTTGGCCGGACTTTATTACTCCGCGTGTAGGTAAGGGCATAATGAAACGAAATAGTCTCACCTTATCTAAAGACAGAAGCAGAAACCAATAGAAGCAATCATCAACCCGACCAACATTAAAGACTCGCGGACGCAGCGGCACGCCACGTACTGCGATAGCCTCCTACCGCACGCCCCTGATAAGGGCCACACGCACCTCGCCAAATATACGAATGACAAGAATTTGAGGTTGGGGTTCTAGCGGACCCCCACTTCACATCACACTAGTGATACCCACGTCCGTTACTTCACAAGATGGGCGATCTTTAGATCCACGGGCTTCCAGATGGTTAGAAGGTGTTGCCGCATCCCTCCTTAATGCTACACCAAGGATGAAGACTGATCTCGCACTCCGACTGCAAAGCCCGGACGTTGGTCCTAGCTCATCCTACAGGCCACATAGTGATAACACAACATAACCTCCCACCGTACGACGTAAATACACTTGGAAGACTGTTCATATCAACAAAAACGGCAAAGAAC\n",
      "A: 3 0 2 1 2 1 2 0 2 1 5 4 2 2 2 1 2 2 1 3 3 1 1 4 2 2 0 2 0 3 1 4 2 3 2 1 4 2 1 2 2 3 3 2 5 3 1 4 2 1 1 4 2 3 3 2 4 3 0 4 5 2 3 2 2 3 1 3 3 3 2 5 1 3 3 2 5 1 3 2 3 4 2 3 3 1 1 3 2 3 2 3 3 3 5 2 2 5 3 0 3 2 4 4 0 1 2 2 2 4 2 5 2 4 1 2 0 2 2 2 4 0 2 3 1 3 3 1 2 2 2 0 3 1 3 3 2 2 1 2 2 2 2 2 0 1 2 1 3 2 4 3 4 3 3 2 4 4 4 1 1 2 2 1 1 2 2 3 5 4 4 5 4 3 1 2 4 3 2 2 2 3 4 4 5 3 2 2 3 1 4 5 2 3 1 3 4 1 1 1 2 4 2 5 3 1 2 2 1 1 1 2 1 2 3 5 0 3 3 2 1 0 3 4 1 3 2 3 3 1 1 1 3 2 2 4 3 1 3 2 3 1 3 2 1 4 1 3 2 3 3 6 4 1 4 2 3 4 2 1 1 4 4 3 0 4 2 4 3 2 2 3 5 4 2 3 2 1 4 1 2 0 1 1 1 2 5 2 3 2 3 1 6 2 1 2 3 3 3 3 5 3 3 3 3 2 3 5 0 1 3 1 2 5 4 4 2 5 3 1 3 3 1 1 1 3 6 4 4 2 3 2 6 2 2 1 3 2 2 1 3 3 5 5 2 3 0 2 1 3 4 1 2 3 3 4 3 5 2 3 1 3 0 5 2 4 2 2 1 5 2 1 4 2 3 1 2 1 6 1 1 3 4 3 4 3 5 1 2 2 3 2 3 2 2 3 2 4 3 1 2 1 2 3 3 3 0 4 2 2 2 5 2 4 2 4 3 0 1 2 1 1 3 5 3 2 2 7 1 5 1 3 2 5 4 3 5 1 4 3 3 4 4 4 2 2 1 1 1 3 1 1 2 2 1 1 3 5 3 3 1 2 3 1 3 5 3 3 2 2 3 1 3 0 3 4 7 1 2 1 4 4 0 2 0 2 5 1 4 5 3 2 4 4 4 1 1 4 4 3 2 5 1 2 3 2 0 3 2 1 3 3 3 2 1 0 4 7 4 2 3 3 3 3 6 6 3 2 3 2 3 5 4 2 2 4 4 2 5 2 4 3 2 2 4 5 2 2 3 1 1 3 3 1 1 2 3 3 4 3 3 4 1 5 1 3 4 3 4 1 4 2 3 2 1 2 3 2 3 2 1 1 3 3 3 1 3 3 4 1 1 1 2 4 2 1 0 3 4 0 3 2 3 5 1 5 3 2 3 2 1 2 1 3 0 2 3 1 5 1 2 1 3 3 1 2 2 3 3 4 3 1 0 2 3 3 4 3 6 3 2 3 4 1 1 3 2 0 3 2 3 4 5 3 4 2 5 2 3 3 5 2 2 4 2 3 3 1 3 4 2 3 1 2 3 3 3 3 2 2 2 1 1 3 1 3 0 3 2 2 0 2 4 2 2 1 0 2 5 2 0 3 2 3 2 4 0 1 4 2 4 1 3 4 1 2 2 5 2 4 2 2 1 3 2 2 3 2 0 1 0 2 3 1 2 3 2 4 2 4 5 1 3 2 2 2 3 2 2 3 3 2 2 2 2 4 2 4 1 0 3 3 1 2 0 3 2 3 3 3 2 5 0 4 3 1 2 3 3 4 1 4 5 1 3 3 2 3 2 1 2 3 0 1 4 2 0 1 2 1 1 2 2 2 3 3 2 2 1 3 4 2 4 2 2 4 4 3 2 4 2 2 4 3 1 3 2 0 2 6 2 1 3 2 1 2 5 2 1 1 2 2 3 1 3 2 1 6 3 4 1 1 1 2 2 2 5 2 2 2 1 2 2 0 1 2 1 5 2 1 3 2 3 2 1 2 2 4 1 4 2 2 1 2 4 2 4 3 5 2 2 1 4 1 4 4 3 3 2 3 5 1 4 0 3 4 2 1 2 2 1 1 4 0 2 1 1 4 3 2 3 2 3 3 4 4 3 1 5 2 4 2 2 3 2 2 4 3 2 6 1 1 1 0 1 2 5 1 4 2 1 3 5 1 3 3 3 6 4 2 2 1 1 4 4 4 0 3 6 0\n",
      "C: 2 7 3 3 1 2 4 3 1 1 1 3 2 1 3 4 2 2 3 4 2 2 4 2 6 3 3 4 4 2 5 2 1 3 2 4 3 3 4 4 1 0 3 2 3 1 5 0 2 3 2 1 1 1 2 2 2 2 4 0 1 3 3 2 1 1 5 1 1 3 3 0 2 2 2 3 2 3 3 4 2 1 3 1 3 4 3 4 1 2 3 3 4 1 1 1 3 1 3 5 5 1 3 1 4 3 3 2 4 3 6 1 3 2 2 1 2 3 3 2 3 3 6 2 2 1 1 4 4 1 4 1 1 2 1 5 1 3 1 4 3 1 3 2 5 1 3 2 2 3 2 2 2 2 4 4 4 1 4 3 4 2 4 0 4 3 1 2 0 2 4 1 3 2 5 3 1 2 3 2 2 1 1 2 2 2 2 4 3 3 2 2 5 4 3 2 2 3 3 3 1 3 3 4 2 5 3 1 3 2 4 5 3 2 2 1 1 1 1 5 4 4 2 1 1 6 0 3 4 2 3 3 3 5 4 5 1 2 3 5 1 5 4 1 2 2 5 4 2 2 2 2 2 3 3 4 1 2 4 6 4 3 2 1 1 2 1 1 3 2 1 5 3 5 3 4 2 6 4 2 2 6 5 3 2 3 2 3 4 3 5 2 0 3 2 4 2 1 2 3 2 2 0 4 1 5 4 2 3 3 1 2 1 1 0 3 5 2 3 4 5 4 2 2 4 2 2 2 2 3 1 4 2 2 3 5 2 5 2 5 4 3 3 0 2 3 3 2 5 2 1 3 3 1 2 1 2 4 2 2 1 4 3 1 1 2 4 3 1 2 3 3 2 3 1 4 3 1 2 0 2 3 1 4 3 4 1 2 0 3 4 1 1 5 1 3 2 1 1 7 2 2 4 0 2 1 2 1 2 2 2 1 3 4 2 0 1 3 2 2 3 1 3 2 1 2 3 1 3 3 1 1 2 3 4 4 1 4 2 2 3 1 2 2 3 6 2 4 4 0 3 2 3 3 4 2 0 2 4 2 2 2 2 2 3 2 5 1 4 5 1 7 1 1 1 0 2 3 2 3 3 2 2 3 3 3 2 2 4 1 2 0 3 1 1 4 3 3 2 1 3 1 1 2 4 2 4 2 5 5 2 2 2 3 5 3 1 1 4 0 1 4 2 0 2 2 3 4 2 3 2 0 1 4 3 2 0 1 1 1 1 2 3 5 4 4 0 4 1 3 4 2 1 5 4 5 1 2 6 4 1 4 6 1 1 0 2 2 3 2 4 4 1 3 3 5 1 2 3 3 2 5 2 1 4 2 3 4 4 5 3 5 4 2 4 2 1 2 5 3 0 4 3 1 2 2 0 3 4 1 3 3 3 3 5 4 2 3 1 5 3 5 4 4 5 1 3 3 2 2 2 0 3 2 4 4 2 4 2 4 2 4 1 4 4 0 5 2 4 5 3 1 1 0 1 2 0 6 2 3 2 1 2 2 3 3 3 2 2 2 3 0 2 1 2 0 1 2 2 2 2 1 3 0 2 5 4 1 2 5 3 2 2 3 4 4 4 3 2 3 3 2 5 3 4 3 3 4 1 3 1 4 3 3 3 2 2 1 3 3 4 4 4 2 5 3 0 3 5 3 2 0 3 4 2 1 4 1 4 3 2 1 2 2 3 0 3 4 1 1 3 4 2 2 3 2 3 1 0 5 4 3 4 3 3 2 4 1 1 4 4 3 3 2 2 2 2 2 2 2 2 1 2 1 2 2 3 3 3 2 3 4 2 4 2 0 5 3 5 2 3 3 2 3 2 2 0 2 3 0 3 3 0 3 4 2 2 1 0 2 3 2 4 2 2 3 6 4 3 0 1 4 2 4 2 4 1 3 2 3 3 0 1 3 1 2 5 1 3 2 1 4 4 3 2 1 3 6 2 2 3 2 2 4 4 4 1 2 2 5 0 4 3 1 4 4 2 0 4 0 2 2 5 6 1 5 4 2 1 2 1 2 4 2 1 2 4 3 3 1 1 4 1 3 2 3 5 4 3 4 3 4 1 4 3 3 1 3 4 2 1 3 2 1 3 2 2 3 1 5 3 4 0 1 3 2 1 3 2 1 4 0 1 3 3 3 3 3 3 1 4 2 0 5 2 2 2 2 2 4 2 3 3 2 3 2 4 2 1 5\n",
      "G: 1 3 2 4 2 2 2 4 2 2 3 1 5 3 1 1 1 5 4 2 1 1 2 2 2 2 6 2 2 2 0 3 4 2 4 4 1 3 3 4 3 3 3 1 1 3 4 2 3 4 2 2 2 4 3 3 3 3 4 1 1 4 3 2 2 2 2 1 2 2 4 2 3 3 1 4 1 3 2 2 2 2 2 2 3 0 2 1 4 5 3 1 3 2 2 2 3 3 3 2 1 4 2 5 2 4 3 4 2 3 1 4 0 2 6 2 6 4 2 3 2 1 1 4 1 3 4 1 1 4 2 4 1 2 3 0 3 1 5 2 1 5 3 1 2 5 2 4 0 3 2 4 1 3 1 1 1 4 1 3 2 2 2 4 4 3 3 3 5 3 0 2 1 2 2 5 4 4 2 3 2 3 4 3 1 3 4 3 2 5 1 2 1 1 4 4 3 2 4 5 5 1 3 1 3 0 3 2 1 3 5 2 1 1 2 3 6 4 1 2 2 2 3 2 5 0 5 2 2 4 2 3 3 1 2 1 4 6 3 2 5 3 1 6 3 2 1 3 4 1 2 1 1 2 0 1 1 2 1 2 3 1 2 4 5 1 3 2 3 3 5 0 0 0 1 2 1 2 1 3 2 3 4 4 3 2 2 2 1 3 1 5 2 5 5 2 3 3 2 0 2 3 5 3 2 0 2 2 4 3 4 4 5 1 2 2 1 1 2 4 1 0 6 4 3 1 2 3 2 3 4 4 0 3 2 2 0 2 3 2 1 3 0 3 3 1 4 3 1 2 3 4 3 1 2 2 1 0 2 3 6 2 2 2 4 2 2 2 4 2 3 3 1 2 3 4 2 6 1 4 2 2 3 2 1 1 1 4 4 4 1 3 5 2 4 3 4 1 3 0 3 2 3 1 3 4 6 2 6 5 5 3 2 1 2 4 3 5 3 4 5 5 2 1 3 0 3 1 4 0 2 4 3 1 2 1 1 3 4 3 2 2 3 1 1 1 4 3 3 2 2 4 4 2 3 4 5 3 2 1 1 2 2 1 0 3 1 2 1 0 4 1 4 3 4 1 1 5 4 2 0 1 6 5 6 3 3 3 2 3 1 4 1 2 3 2 4 3 2 3 1 3 5 2 2 2 4 3 1 3 1 1 3 1 3 3 2 1 1 4 3 2 3 5 1 1 4 3 3 4 3 3 3 1 2 2 3 3 3 6 2 3 4 1 1 1 3 2 3 1 2 2 3 2 1 0 4 3 0 0 3 1 1 3 2 3 2 2 1 5 1 2 1 3 6 2 4 3 3 2 4 1 3 4 1 5 4 3 1 2 4 3 2 1 3 5 4 3 0 3 4 3 4 0 2 2 5 2 0 2 3 2 1 2 4 3 4 3 0 2 4 3 3 2 2 2 5 2 1 1 2 6 5 3 2 1 3 0 1 2 5 3 3 3 2 3 0 5 0 1 3 2 0 3 4 1 2 0 4 2 3 3 4 3 2 2 1 4 2 1 0 3 3 4 3 5 4 1 2 4 4 4 4 3 2 2 1 3 5 2 6 3 2 2 3 2 2 3 2 2 3 1 2 2 4 2 2 3 3 2 3 4 0 2 4 2 3 2 0 2 2 2 2 2 2 4 2 3 3 5 3 3 2 1 1 2 2 2 2 2 2 5 3 2 4 5 4 2 5 3 0 2 2 2 1 0 4 4 4 2 2 2 3 5 4 4 3 2 1 2 2 2 5 0 1 5 5 1 1 3 4 2 1 6 4 1 4 0 1 6 2 2 4 1 2 3 1 3 2 2 3 3 2 1 2 2 2 3 3 3 2 3 4 2 2 2 2 5 5 2 1 4 2 3 4 2 1 1 5 3 1 3 1 1 4 2 3 2 3 3 3 5 3 3 2 3 2 2 3 2 4 4 4 2 4 4 1 0 4 2 2 3 3 0 2 4 1 0 6 2 3 1 3 3 4 1 2 3 1 3 4 5 4 2 3 0 1 1 3 3 3 4 1 3 3 2 2 3 3 3 3 2 3 3 3 2 1 4 1 2 3 3 1 2 3 4 3 2 1 4 3 2 4 2 3 3 2 1 3 1 2 2 2 2 4 3 2 2 5 2 3 3 4 3 2 2 1 1 2 2 1 2 3 3 2 3 2 2 1 1 4 4 3 3 1 2 5 2 3 3\n",
      "T: 4 0 3 2 5 5 2 3 5 6 1 2 1 4 4 4 5 1 2 1 4 6 3 2 0 3 1 2 4 3 4 1 3 2 2 1 2 2 2 0 4 4 1 5 1 3 0 4 3 2 5 3 5 2 2 3 1 2 2 5 3 1 1 4 5 4 2 5 4 2 1 3 4 2 4 1 2 3 2 2 3 3 3 4 1 5 4 2 3 0 2 3 0 4 2 5 2 1 1 3 1 3 1 0 4 2 2 2 2 0 1 0 5 2 1 5 2 1 3 3 1 6 1 1 6 3 2 4 3 3 2 5 5 5 3 2 4 4 3 2 4 2 2 5 3 3 3 3 5 2 2 1 3 2 2 3 1 1 1 3 3 4 2 5 1 2 4 2 0 1 2 2 2 3 2 0 1 1 3 3 4 3 1 1 2 2 2 1 2 1 3 1 2 2 2 1 1 4 2 1 2 2 2 0 2 4 2 5 5 4 0 1 5 5 3 1 3 2 5 1 3 4 2 3 3 1 3 2 1 3 4 3 1 2 2 0 2 1 1 1 1 1 2 1 4 2 3 0 2 4 3 1 3 4 3 3 5 2 3 1 2 2 2 2 4 3 4 3 1 3 2 2 2 1 4 1 5 1 1 4 4 1 0 2 4 3 1 3 2 2 1 2 2 0 2 2 2 3 3 4 1 2 2 0 4 3 1 1 3 3 2 3 2 3 4 1 2 2 2 1 1 3 1 3 2 4 0 1 2 2 2 0 2 3 3 2 5 1 3 2 2 1 2 2 3 3 3 3 3 3 2 2 2 5 3 3 4 1 4 2 2 1 5 2 3 2 2 3 4 1 2 3 3 3 3 1 3 2 1 5 5 2 2 1 2 2 3 3 4 1 2 4 1 1 3 1 2 4 3 2 3 5 1 6 2 2 2 3 0 1 1 1 3 1 4 2 3 2 4 2 1 3 2 2 3 6 2 1 2 2 6 2 3 1 0 2 3 2 0 2 2 3 1 3 4 1 3 2 2 5 4 3 1 3 2 3 2 0 1 4 6 4 3 6 4 0 1 4 3 3 2 1 2 6 2 5 0 1 2 4 3 3 2 0 1 2 0 4 0 1 4 4 2 3 2 3 2 0 2 3 4 1 3 4 1 4 2 2 2 1 4 4 2 4 1 4 3 1 1 4 3 1 2 2 1 1 0 1 2 1 2 2 2 3 3 2 3 4 1 1 3 2 1 2 1 0 5 2 3 5 3 3 3 2 4 3 2 2 0 3 3 1 2 1 6 4 2 3 2 2 1 2 5 2 0 1 2 3 1 3 3 3 2 2 2 2 0 0 1 2 2 1 2 3 1 2 5 2 1 4 3 1 0 4 5 1 2 3 3 5 3 3 5 2 1 1 1 3 4 2 1 1 0 1 2 5 0 2 4 3 3 3 2 3 1 2 1 3 1 1 1 0 2 2 3 4 3 3 3 2 1 3 4 4 1 5 3 2 1 2 0 4 2 1 3 2 3 3 3 3 5 4 4 3 2 2 2 4 4 2 2 4 2 4 5 0 5 3 1 1 1 3 2 3 1 3 4 2 1 3 4 4 1 2 0 1 5 2 2 3 2 1 4 1 2 4 3 2 5 1 2 2 3 3 1 1 5 2 2 1 5 5 2 4 5 4 2 3 2 1 1 3 2 4 1 3 0 2 2 3 4 2 4 4 4 4 1 1 5 3 1 2 2 0 3 1 1 4 5 1 2 0 2 4 4 2 1 4 4 1 3 3 2 2 1 4 1 4 4 1 3 1 4 4 2 5 4 3 1 5 3 2 4 4 3 3 6 3 3 4 1 2 2 3 2 2 2 1 3 2 4 2 0 2 3 2 1 5 0 1 6 2 4 3 3 2 1 3 4 3 2 3 3 3 4 3 2 1 1 2 4 1 1 3 2 3 1 2 2 4 4 3 3 6 3 0 7 3 0 2 4 3 1 4 1 3 4 3 4 3 2 1 0 0 2 3 1 4 1 3 4 3 1 4 2 2 1 1 2 3 1 3 2 4 2 1 2 1 4 2 3 2 4 4 2 2 5 1 2 2 3 3 1 4 0 1 3 5 1 2 1 2 6 4 1 3 3 2 1 1 2 6 4 4 4 3 1 5 1 5 4 3 2 1 3 2 3 0 3 3 2 2 3 1 2 2 1 3 0 2\n"
     ]
    }
   ],
   "source": [
    "# 1. create list sequences\n",
    "\n",
    "def fasta_import(filepath):\n",
    "    with open(filepath) as fastafile:\n",
    "        import re\n",
    "        fastafile = fastafile.read()\n",
    "        fastafile = re.sub(r\"Rosalind_\\d+\\n\", \"\", fastafile)\n",
    "        fastafile = fastafile.replace(\"\\n\", \"\")\n",
    "        seq_list = fastafile.split(\">\")\n",
    "        seq_list = seq_list[1:len(seq_list)] \n",
    "        #otherwise first list element is just emtpy space before first >\n",
    "        return seq_list\n",
    "    \n",
    "sequences = fasta_import(\"rosalind_data/rosalind_cons.txt\")\n",
    "\n",
    "\n",
    "# 2. count matrix\n",
    "\n",
    "def count_matrix(sequences):\n",
    "    #create matrix for count: M(b = base, i = Index in seq)\n",
    "        # fill with count for b in i\n",
    "    M = []\n",
    "    for i in range(4): #one list per possible base (ACGT)\n",
    "        M.append([0]*len(sequences[0])) #one index per base in sequences\n",
    "\n",
    "    #fill matrix with counts\n",
    "    # adding 1 for each time b appears in i for any of the sequences\n",
    "    for seq in sequences:\n",
    "        for i in range(len(seq)):\n",
    "            if seq[i] == \"A\":\n",
    "                M[0][i] = M[0][i] + 1\n",
    "            elif seq[i] == \"C\":\n",
    "                M[1][i] = M[1][i] + 1\n",
    "            elif seq[i] == \"G\":\n",
    "                M[2][i] = M[2][i] + 1\n",
    "            elif seq[i] == \"T\":\n",
    "                M[3][i] = M[3][i] + 1\n",
    "                \n",
    "    # print in pretty format\n",
    "    print(\"A:\", \" \".join(map(str, M[0])))\n",
    "    print(\"C:\", \" \".join(map(str, M[1])))\n",
    "    print(\"G:\", \" \".join(map(str, M[2])))\n",
    "    print(\"T:\", \" \".join(map(str, M[3])))\n",
    "    return M\n",
    "\n",
    "M = count_matrix(sequences)      \n",
    "\n",
    "\n",
    "# 3. find consensus sequence\n",
    "\n",
    "def consensus_seq(M):\n",
    "    # retrive \"colums\" of M using zip()\n",
    "    # returns zip object, an iterator of tuples where the first item in \n",
    "    # each passed iterator is paired together, and then the second item in \n",
    "    # each passed iterator are paired together etc.\n",
    "    Mcol = zip(*M)   # *M tells zip to use inner lists (*M = M[0], M[1], M[2], M[3])           \n",
    "    Mcol = list(Mcol)\n",
    "    \n",
    "    # identify most common base at i\n",
    "    consensus = []\n",
    "    for i in range(len(Mcol)):\n",
    "        b_in_i = Mcol[i].index(max(Mcol[i]))\n",
    "        consensus.append(b_in_i)\n",
    "        # if 2 bases with same frequency in i, ONLY the index of first is given out\n",
    "        # exercise does not care which b if two have same frequency\n",
    "        \n",
    "    # turn indices of lists per base into letters for bases\n",
    "    cons_bases = []\n",
    "    bases = [\"A\", \"C\", \"G\", \"T\"]\n",
    "    for i in range(len(consensus)):\n",
    "        for b in bases:\n",
    "            if consensus[i] == bases.index(b):\n",
    "                cons_bases.append(b)\n",
    "    #print(\"\".join(cons_bases))\n",
    "    return cons_bases\n",
    "\n",
    "cons_bases = consensus_seq(M)    \n",
    "\n",
    "\n",
    "# print correct format for exercise:\n",
    "print(\"SOLUTION:\")\n",
    "print(\"\".join(cons_bases))\n",
    "\n",
    "print(\"A:\", \" \".join(map(str, M[0])))\n",
    "print(\"C:\", \" \".join(map(str, M[1])))\n",
    "print(\"G:\", \" \".join(map(str, M[2])))\n",
    "print(\"T:\", \" \".join(map(str, M[3])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e3d04a-8775-44ff-8980-3fe2d094a28a",
   "metadata": {},
   "source": [
    "## GRAPH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4db7a65f-fe88-4ee1-8180-200fc180ae96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rosalind_2295 Rosalind_2066\n",
      "Rosalind_2295 Rosalind_7363\n",
      "Rosalind_2295 Rosalind_5734\n",
      "Rosalind_2295 Rosalind_9263\n",
      "Rosalind_2586 Rosalind_7362\n",
      "Rosalind_2586 Rosalind_9451\n",
      "Rosalind_2586 Rosalind_6656\n",
      "Rosalind_2586 Rosalind_6939\n",
      "Rosalind_2586 Rosalind_7379\n",
      "Rosalind_6217 Rosalind_8972\n",
      "Rosalind_6217 Rosalind_8515\n",
      "Rosalind_6217 Rosalind_1268\n",
      "Rosalind_6217 Rosalind_1058\n",
      "Rosalind_6217 Rosalind_6960\n",
      "Rosalind_6217 Rosalind_4314\n",
      "Rosalind_1578 Rosalind_3461\n",
      "Rosalind_1578 Rosalind_2072\n",
      "Rosalind_5194 Rosalind_3835\n",
      "Rosalind_3947 Rosalind_1703\n",
      "Rosalind_1772 Rosalind_1578\n",
      "Rosalind_1772 Rosalind_8834\n",
      "Rosalind_1772 Rosalind_2156\n",
      "Rosalind_7755 Rosalind_4923\n",
      "Rosalind_1027 Rosalind_7968\n",
      "Rosalind_1027 Rosalind_5564\n",
      "Rosalind_1027 Rosalind_1928\n",
      "Rosalind_1027 Rosalind_1354\n",
      "Rosalind_5284 Rosalind_1772\n",
      "Rosalind_5284 Rosalind_6559\n",
      "Rosalind_6694 Rosalind_1061\n",
      "Rosalind_7968 Rosalind_7362\n",
      "Rosalind_7968 Rosalind_9451\n",
      "Rosalind_7968 Rosalind_6656\n",
      "Rosalind_7968 Rosalind_6939\n",
      "Rosalind_7968 Rosalind_7379\n",
      "Rosalind_5649 Rosalind_1703\n",
      "Rosalind_1703 Rosalind_3413\n",
      "Rosalind_0068 Rosalind_9824\n",
      "Rosalind_3434 Rosalind_0757\n",
      "Rosalind_3434 Rosalind_3449\n",
      "Rosalind_0757 Rosalind_8019\n",
      "Rosalind_0757 Rosalind_4240\n",
      "Rosalind_7986 Rosalind_2119\n",
      "Rosalind_7986 Rosalind_6250\n",
      "Rosalind_7362 Rosalind_9824\n",
      "Rosalind_8361 Rosalind_5284\n",
      "Rosalind_9575 Rosalind_7116\n",
      "Rosalind_9575 Rosalind_4311\n",
      "Rosalind_9575 Rosalind_5687\n",
      "Rosalind_7770 Rosalind_6555\n",
      "Rosalind_7770 Rosalind_7595\n",
      "Rosalind_5918 Rosalind_8204\n",
      "Rosalind_5918 Rosalind_5316\n",
      "Rosalind_9824 Rosalind_1464\n",
      "Rosalind_8019 Rosalind_3835\n",
      "Rosalind_8972 Rosalind_3947\n",
      "Rosalind_8972 Rosalind_2719\n",
      "Rosalind_8972 Rosalind_8639\n",
      "Rosalind_2119 Rosalind_1726\n",
      "Rosalind_3461 Rosalind_1772\n",
      "Rosalind_3461 Rosalind_6559\n",
      "Rosalind_2114 Rosalind_9575\n",
      "Rosalind_2114 Rosalind_5292\n",
      "Rosalind_8834 Rosalind_3835\n",
      "Rosalind_8398 Rosalind_6694\n",
      "Rosalind_8398 Rosalind_6626\n",
      "Rosalind_8398 Rosalind_6474\n",
      "Rosalind_2158 Rosalind_2586\n",
      "Rosalind_2158 Rosalind_7734\n",
      "Rosalind_6250 Rosalind_1123\n",
      "Rosalind_6250 Rosalind_4079\n",
      "Rosalind_4240 Rosalind_4923\n",
      "Rosalind_7087 Rosalind_2066\n",
      "Rosalind_7087 Rosalind_7363\n",
      "Rosalind_7087 Rosalind_5734\n",
      "Rosalind_7087 Rosalind_9263\n",
      "Rosalind_8515 Rosalind_9575\n",
      "Rosalind_8515 Rosalind_5292\n",
      "Rosalind_5292 Rosalind_2158\n",
      "Rosalind_1616 Rosalind_7362\n",
      "Rosalind_1616 Rosalind_9451\n",
      "Rosalind_1616 Rosalind_6656\n",
      "Rosalind_1616 Rosalind_6939\n",
      "Rosalind_1616 Rosalind_7379\n",
      "Rosalind_4916 Rosalind_1464\n",
      "Rosalind_2719 Rosalind_5284\n",
      "Rosalind_3410 Rosalind_3434\n",
      "Rosalind_1765 Rosalind_6555\n",
      "Rosalind_1765 Rosalind_7595\n",
      "Rosalind_4046 Rosalind_7617\n",
      "Rosalind_7657 Rosalind_1703\n",
      "Rosalind_2066 Rosalind_7626\n",
      "Rosalind_0564 Rosalind_2295\n",
      "Rosalind_0564 Rosalind_1964\n",
      "Rosalind_7116 Rosalind_3434\n",
      "Rosalind_7363 Rosalind_1765\n",
      "Rosalind_5734 Rosalind_3410\n",
      "Rosalind_5734 Rosalind_4994\n",
      "Rosalind_5734 Rosalind_7760\n",
      "Rosalind_5734 Rosalind_4608\n",
      "Rosalind_6626 Rosalind_7755\n",
      "Rosalind_6626 Rosalind_0564\n",
      "Rosalind_6626 Rosalind_9586\n",
      "Rosalind_6656 Rosalind_6555\n",
      "Rosalind_6656 Rosalind_7595\n",
      "Rosalind_6559 Rosalind_5918\n",
      "Rosalind_6559 Rosalind_7657\n",
      "Rosalind_4994 Rosalind_4046\n",
      "Rosalind_7304 Rosalind_7968\n",
      "Rosalind_7304 Rosalind_5564\n",
      "Rosalind_7304 Rosalind_1928\n",
      "Rosalind_7304 Rosalind_1354\n",
      "Rosalind_6939 Rosalind_8361\n",
      "Rosalind_6939 Rosalind_4916\n",
      "Rosalind_9586 Rosalind_8204\n",
      "Rosalind_9586 Rosalind_5316\n",
      "Rosalind_7760 Rosalind_1027\n",
      "Rosalind_9040 Rosalind_6217\n",
      "Rosalind_9040 Rosalind_8398\n",
      "Rosalind_1123 Rosalind_7770\n",
      "Rosalind_1726 Rosalind_7770\n",
      "Rosalind_2013 Rosalind_0068\n",
      "Rosalind_3449 Rosalind_2066\n",
      "Rosalind_3449 Rosalind_7363\n",
      "Rosalind_3449 Rosalind_5734\n",
      "Rosalind_3449 Rosalind_9263\n",
      "Rosalind_4079 Rosalind_8792\n",
      "Rosalind_5564 Rosalind_0757\n",
      "Rosalind_5564 Rosalind_3449\n",
      "Rosalind_6474 Rosalind_7716\n",
      "Rosalind_6474 Rosalind_1616\n",
      "Rosalind_1058 Rosalind_7617\n",
      "Rosalind_6960 Rosalind_9575\n",
      "Rosalind_6960 Rosalind_5292\n",
      "Rosalind_4314 Rosalind_8019\n",
      "Rosalind_4314 Rosalind_4240\n",
      "Rosalind_1928 Rosalind_6555\n",
      "Rosalind_1928 Rosalind_7595\n",
      "Rosalind_7626 Rosalind_2119\n",
      "Rosalind_7626 Rosalind_6250\n",
      "Rosalind_7595 Rosalind_4923\n",
      "Rosalind_1354 Rosalind_5649\n",
      "Rosalind_2156 Rosalind_3835\n",
      "Rosalind_4311 Rosalind_1703\n",
      "Rosalind_8639 Rosalind_1703\n",
      "Rosalind_2072 Rosalind_1703\n",
      "Rosalind_3413 Rosalind_2586\n",
      "Rosalind_3413 Rosalind_7734\n",
      "Rosalind_7379 Rosalind_8019\n",
      "Rosalind_7379 Rosalind_4240\n",
      "Rosalind_5687 Rosalind_1464\n",
      "Rosalind_4608 Rosalind_6555\n",
      "Rosalind_4608 Rosalind_7595\n",
      "Rosalind_9263 Rosalind_7755\n",
      "Rosalind_9263 Rosalind_0564\n",
      "Rosalind_9263 Rosalind_9586\n"
     ]
    }
   ],
   "source": [
    "# import sequences\n",
    "def fasta_import(filepath):\n",
    "    with open(filepath) as fastafile:\n",
    "        fastafile = fastafile.read()\n",
    "        fastafile = fastafile.replace(\"\\n\", \"\")\n",
    "        seq_list = fastafile.split(\">\")\n",
    "        seq_list = seq_list[1:len(seq_list)]\n",
    "        return seq_list\n",
    "    \n",
    "# directory with each sequence + roslind ID\n",
    "def make_lists(seq_list):\n",
    "    IDs = []\n",
    "    for i, seq in enumerate(seq_list):\n",
    "        ID = seq[0:13]\n",
    "        IDs.insert(i, ID)\n",
    "    \n",
    "    sequences = []\n",
    "    for i, seq in enumerate(seq_list):\n",
    "        sequence = seq[13:]\n",
    "        sequences.insert(i, sequence)\n",
    "    return sequences, IDs\n",
    "\n",
    "\n",
    "# determine edges\n",
    "\n",
    "def edges(seqs, IDs):\n",
    "    edges = []\n",
    "    for value1 in seqs:\n",
    "        pattern = value1[-3:]\n",
    "        for value2 in seqs:\n",
    "            if value2.startswith(pattern) and value1 != value2:\n",
    "                edges.append([IDs[seqs.index(value1)], IDs[seqs.index(value2)]])\n",
    "    return edges\n",
    "\n",
    "# perform functions\n",
    "seq_list = fasta_import(\"rosalind_data/rosalind_grph.txt\")\n",
    "seqs, IDs = make_lists(seq_list)\n",
    "edges = edges(seqs, IDs)          \n",
    "\n",
    "# print pretty\n",
    "for i in range(len(edges)):\n",
    "    print(\" \".join(edges[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f193fed-8ce5-4cc4-81bb-4a133c0b21b6",
   "metadata": {},
   "source": [
    "## IEV:    calculate average number of dominant phenotype offspring\n",
    "Given: Six nonnegative integers, each of which does not exceed 20,000. The integers correspond to the number of couples in a population possessing each genotype pairing for a given factor. In order, the six given integers represent the number of couples having the following genotypes:\n",
    "AA-AA\n",
    "AA-Aa\n",
    "AA-aa\n",
    "Aa-Aa\n",
    "Aa-aa\n",
    "aa-aa\n",
    "\n",
    "Return: The expected number of offspring displaying the dominant phenotype in the next generation, under the assumption that every couple has exactly two offspring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1c75b3f7-d6e0-4d2b-be7e-cc0f7be53993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "155009.0"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dom_offspring(pathfile):\n",
    "    with open(pathfile) as file:\n",
    "        pairs = file.read()\n",
    "        pairs = [int(num) for num in pairs.split()] #.split() by default at \" \"\n",
    "    P_100 = sum(pairs[0:3])\n",
    "    P_75 = pairs[3]\n",
    "    P_50 = pairs[4]\n",
    "    average_dom = 2 * (P_100 + P_75 * 0.75 + P_50 * 0.5) # 2 offspring per pair\n",
    "    return average_dom\n",
    "\n",
    "dom_offspring(\"rosalind_data/rosalind_iev.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d711522-15e4-47df-9678-43a9d8d1e431",
   "metadata": {},
   "source": [
    "## LCSM: finding a shared motif\n",
    "\n",
    "Given: A collection of k (k≤100) DNA strings of length at most 1 kbp each in FASTA format.\n",
    "\n",
    "Return: A longest common substring of the collection. (If multiple solutions exist, you may return any single solution.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e7a5205f-2817-4afb-81b2-0785b09cd0d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Motif is GAGCAATACCTAGTCTACAGTCTCGTTTCAGAGGCTGAGTCAACACAAACCGTTGTTAGCTTCCGTACTTAAGAAAAGTCGGAATTGGTGAATTGACAGGTCTGTCTAAAACCAGTCGGGCGAAGTCTTTCGGTTAATACAAAAGACCAGTTCAGGGAAAGAGTGGGCCGTAGCTAGGGTCGTGTTCCTTAAGAAGCCCCAAAGCTTTACAGGTTAGAACGATAAAGCCTAACAGGTCTGGTCCCCGCTGCCCGCCA\n",
      "1 motifs found at length 257\n"
     ]
    }
   ],
   "source": [
    "# 1. Import sequences\n",
    "def fasta_import_seq_only(filepath):\n",
    "    with open(filepath) as fastafile:\n",
    "        fastafile = fastafile.read()\n",
    "        seq_list = fastafile.split(\">\")\n",
    "        seq_list = seq_list[1:] # remove first empty element (split before >)\n",
    "    sequences = []\n",
    "    for i, seq in enumerate(seq_list):\n",
    "        import re\n",
    "        sequence = seq[seq.index(\"\\n\")+1:] # +1 excludes \\n from sequence\n",
    "        sequence = sequence.replace(\"\\n\", \"\")\n",
    "        sequences.insert(i, sequence)\n",
    "    return sequences\n",
    "\n",
    "all_seqs = fasta_import_seq_only(\"rosalind_data/rosalind_lcsm.txt\")            \n",
    "\n",
    "# 2. identify length of longest shared element\n",
    "def identify_shared_motif(all_seqs):\n",
    "    l_1 = len(all_seqs[0])\n",
    "    found = False\n",
    "    sub_length = l_1                                    # longest possible sub-string\n",
    "    while not found and sub_length:                     # Loop, over decreasing lengths of sub-string\n",
    "        for start in range(l_1 - sub_length + 1):       # Loop, over all start-positions of possible sub-strings \n",
    "            sub_str = all_seqs[0][start:(start+sub_length)]     # Get the sub-string\n",
    "            if all(sub_str in seq for seq in all_seqs): # If found a match for the sub-string, in ALL other seqs\n",
    "                found = True                            # Stop trying with smaller lengths of sub-string (stop while loop)\n",
    "                break                                   # Stop trying with this length of sub-string (stop for loop)\n",
    "        if not found:                                   # If no matches found for this length of sub-string\n",
    "            sub_length -= 1                             # Let's try a smaller length for the sub-strings\n",
    "    \n",
    "    print (f\"Motif is {sub_str}\" if found else \":/\")\n",
    "    return sub_str\n",
    "\n",
    "identify_shared_motif(all_seqs)\n",
    "\n",
    "# challenge: modify to find all shared motifs of max length\n",
    "def identify_all_shared_motif(all_seqs):\n",
    "    l_1 = len(all_seqs[0])\n",
    "    found = False\n",
    "    sub_length = l_1\n",
    "    longest_motifs = []\n",
    "    while not found and sub_length:\n",
    "        for start in range(l_1 - sub_length + 1):\n",
    "            sub_str = all_seqs[0][start:(start+sub_length)]\n",
    "            if all(sub_str in seq for seq in all_seqs):\n",
    "                found = True\n",
    "                longest_motifs.append(sub_str)\n",
    "        if not found:                                   \n",
    "            sub_length -= 1                             \n",
    "    \n",
    "    print (f\"{len(longest_motifs)} motifs found at length {sub_length}\" if found else \":/\")\n",
    "    return longest_motifs\n",
    "\n",
    "motifs = identify_all_shared_motif(all_seqs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eaf889b-f885-4b44-af0a-ea1d5fbd44e4",
   "metadata": {},
   "source": [
    "## LIA: Independent Alleles\n",
    "Given: Two positive integers k (k≤7) and N (N≤2k). In this problem, we begin with Tom, who in the 0th generation has genotype Aa Bb. Tom has two children in the 1st generation, each of whom has two children, and so on. Each organism always mates with an organism having genotype Aa Bb.\n",
    "\n",
    "Return: The probability that at least N Aa Bb organisms will belong to the k-th generation of Tom's family tree (don't count the Aa Bb mates at each level). Assume that Mendel's second law holds for the factors.\n",
    "    \n",
    "P(Aa) * P(Ba) = P(AaBb) because of 2nd mendalian law (independent inheritance)\n",
    "\n",
    "P(Aa) = P(Bb) = 0.5 per individual because all parent pairs contain at least one AaBb\n",
    "\n",
    "    k = generation\n",
    "    N = number of AaBb individuals\n",
    "    T = 2**k total individuals in generation\n",
    "    P = probability of N in k WANTED\n",
    "\n",
    "used binominal contribution for at least N \"successes\"(AaBb) in T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cdab06a0-1d23-493c-964b-f6359dd50c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of at least 9 AaBb individuals after 5 generations is 0.406\n"
     ]
    }
   ],
   "source": [
    "# 1. Import N and k, define variables\n",
    "with open(\"rosalind_data/rosalind_lia.txt\") as file:\n",
    "    file = file.read()\n",
    "    file = file.split(\" \")\n",
    "    k = int(file[0]) # generation\n",
    "    N = int(file[1]) # AaBb individuals in generation\n",
    "    T = 2 ** k  # total individuals in generation\n",
    "    p = 0.25    # probability of AaBb per individual\n",
    "    \n",
    "\n",
    "# 2. P for N individuals with AaBb\n",
    "from math import comb\n",
    "P = []\n",
    "for n in range(N,T+1):# range excludes last number, T+1 to include T in range\n",
    "   Pn = comb(T, n) * p**n  * (1-p)**(T-n)\n",
    "   P.insert(n, Pn)\n",
    "print(f\"Probability of at least {N} AaBb individuals after {k} generations is {round(sum(P), ndigits=3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ddbc60a-a08c-4b2f-ab22-6e9edce05274",
   "metadata": {},
   "source": [
    "## MPRT: Finding a Protein Motif \n",
    "**lookahead** needed. Otherwise only non-overlapping motifs are detected.\n",
    "* Usually overlaps are not found because finditer consumes the characters after checking\n",
    "* lookahead checks for a specific pattern ahead of the current position without consuming characters in the input string\n",
    "\n",
    "Given: At most 15 UniProt Protein Database access IDs.\n",
    "\n",
    "Return: For each protein possessing the N-glycosylation motif, output its given access ID followed by a list of locations in the protein string where the motif can be found. The protein motif is represented by a shorthand as follows: [XY] means \"either X or Y\" and {X} means \"any amino acid except X.\" For example, the N-glycosylation motif is written as N{P}[ST]{P}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bcb3750-235b-4190-97c9-9c8d81bf9e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P01374_TNFB_HUMAN\n",
      "96\n",
      "P01047_KNL2_BOVIN\n",
      "47 87 168 169 197 204 280\n",
      "Q00001_RHGA_ASPAC\n",
      "50 235 317\n",
      "Q8ER84\n",
      "33\n",
      "P07585_PGS2_HUMAN\n",
      "211 262 303\n",
      "P13838_LEUK_RAT\n",
      "274 300\n",
      "P19835_BAL_HUMAN\n",
      "207\n",
      "Q640N1\n",
      "471 519 913 1030\n",
      "B5ZC00\n",
      "85 118 142 306 395\n",
      "P00748_FA12_HUMAN\n",
      "249 433\n",
      "P33515\n",
      "157 243 339 399 411 575 611 794 896 993 1027 1351 1450 1683 1692 1830 1886 2172 2266 2488 2656 2716 2817\n"
     ]
    }
   ],
   "source": [
    "# 1. import uniprot ID and paste into link\n",
    "with open(\"rosalind_data/rosalind_mprt.txt\") as file:\n",
    "    file = file.readlines()\n",
    "    links = []\n",
    "    NamesRL = []\n",
    "    for i in file:\n",
    "        iS = i.strip() #\\n at end of ID must be removed, iS for insert i to work\n",
    "        Name = iS  # retrieve rosalinds used full name for output\n",
    "        NamesRL.insert(file.index(i), Name)\n",
    "        if \"_\" in iS: iS = iS[0:iS.index(\"_\")] # get pure ID\n",
    "        link = f\"http://www.uniprot.org/uniprot/{iS}.fasta\"\n",
    "        # print(repr(link)) for debugging if needed\n",
    "        links.insert(file.index(i), link)\n",
    "        \n",
    "        \n",
    "# 2. retrieve protein sequence\n",
    "import requests\n",
    "seqs = []\n",
    "for i in range(len(links)):\n",
    "    response = requests.get(links[i])\n",
    "    seq = response.text\n",
    "    seq = repr(seq)\n",
    "    seq = seq[seq.index(\"\\\\n\"):]\n",
    "    seq = seq.replace(\"\\\\n\", \"\")\n",
    "    seq = seq[0:seq.index( \"'\" )]\n",
    "    \n",
    "    seqs.insert(i, seq)\n",
    "\n",
    "repr(seq)\n",
    "\n",
    "\n",
    "# 3. find motif\n",
    "import re\n",
    "pattern = r\"N[^P][ST][^P]\"\n",
    "Output = []\n",
    "\n",
    "for seq in seqs:\n",
    "    matches = re.finditer(f\"(?={pattern})\", seq) #LOOKAHEAD (?=)\n",
    "    position = []\n",
    "    for m in matches: position.append((m.start()+1))\n",
    "    Output.append(position)\n",
    "    \n",
    "# 4. print pretty\n",
    "for i in range(len(seqs)):\n",
    "    if Output[i]:  # Check if Output[i] is non-empty\n",
    "        print(f\"{NamesRL[i]}\\n{' '.join(map(str, Output[i]))}\")\n",
    "\n",
    "    \n",
    "# lookahead needed to find overlapping matches. \n",
    "# Usually overlaps are not found because finditer consumes the characters after checking\n",
    "# lookahead checks for a specific pattern ahead of the current position without consuming characters in the input string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d99eee-ea55-49d1-97d6-081db39aa399",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
